{"cells":[{"metadata":{},"cell_type":"markdown","source":["# Applying some basic machine learning to the culled dataset of amino acid distances and antigenic distances\n",""]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import sklearn as sk\n","from sklearn import linear_model as sklm\n","from sklearn import svm\n","from sklearn import ensemble\n","from sklearn import grid_search\n","import plotly.plotly as py\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","%pylab inline\n","np.set_printoptions(suppress=True)\n","np.set_printoptions(precision=3)\n","from sklearn.cross_validation import LeaveOneLabelOut\n","from sklearn.cross_validation import cross_val_score\n","from sklearn.preprocessing import PolynomialFeatures\n","import matplotlib.patches as mpatches\n","\n",""],"execution_count":3,"outputs":[{"output_type":"stream","text":"Populating the interactive namespace from numpy and matplotlib\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":["### Using the Regression Data class to read the file into a dataframe and add columns for dates and clusters"]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["df = RegressionData('antigenic-genetic-pret8-positional-no-0-and-upto-10-mutations.csv', dropFirstRow=True).df\n",""],"execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Checking the distribution of the data\n","The data are dominated by strains from the early 1990s"]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["x=plt.hist(df['strain_1_dates'], bins = 35)\n",""],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"<matplotlib.figure.Figure at 0x10ca2ed68>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSVKL4SBJajEcJEkthoMkqeX/AxPMYLtaTxkbAAAAAElFTkSuQmCC\n"},"metadata":{}}]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["x=plt.hist(df['strain_2_dates'], bins = 35)"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"<matplotlib.figure.Figure at 0x1116de710>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":["#### Making x and y sets as well as a train/test split \n",""]},{"metadata":{"trusted":true,"collapsed":false},"cell_type":"code","source":["X = df.drop(['AG1', 'AG2', 'AG-DIST', 'NUM-MUTATIONS', \n","                   'strain_1_dates', 'strain_2_dates', 'cluster1', 'cluster2'], axis = 1)\n","y = df['AG-DIST']\n","\n","train = df.loc[((df['strain_1_dates']<=1994)& (df['strain_2_dates'] <=1994))]\n","\n","test = df.loc[((df['strain_1_dates']>1994) |(df['strain_2_dates'] >1994))]\n","\n","xtrain = train.drop(['AG1', 'AG2', 'AG-DIST', 'NUM-MUTATIONS', \n","                       'strain_1_dates', 'strain_2_dates', 'cluster1', 'cluster2'], axis = 1)\n","ytrain = train['AG-DIST']\n","\n","xtest = test.drop(['AG1', 'AG2', 'AG-DIST', 'NUM-MUTATIONS', \n","                       'strain_1_dates', 'strain_2_dates', 'cluster1', 'cluster2'], axis = 1)\n","ytest = test['AG-DIST']\n","\n","merged = pd.concat([train, test])\n","\n","print(merged.head)\n","assert max(merged.duplicated())==0\n","assert not pd.isnull(merged).values.any()"],"execution_count":50,"outputs":[{"output_type":"stream","text":"<bound method NDFrame.head of               AG1           AG2   AG-DIST  NUM-MUTATIONS  AD124  AE163  AG124  \\\n1         HK/1/89       SU/1/90  0.086823              1      0      0      0   \n2       BI/628/76    BI/2271/76  0.130552              1      0      0      0   \n3      LY/1373/91     PA/490/92  0.161351              1      0      1      0   \n4      LY/1337/91   HO/56798/92  0.232275              1      0      0      0   \n5     LY/23672/91   HO/56798/92  0.236731              1      0      0      0   \n6      GE/6447/91   HO/56798/92  0.242901              1      0      0      0   \n7      LY/1189/91   HO/56829/92  0.267579              1      0      0      0   \n9      BI/5029/76    BI/6545/76  0.288663              1      0      0      0   \n10      NL/823/92     PA/490/92  0.301419              1      0      1      0   \n11     BI/5657/76    BI/6545/76  0.315012              1      0      0      0   \n12      NL/398/93      NL/18/94  0.341004              1      0      0      0   \n13      MA/G12/91     NL/816/91  0.341404              1      0      0      0   \n14       SP/35/89      SP/53/89  0.363517              1      0      0      0   \n15        SG/6/93      YA/56/93  0.366965              1      0      0      0   \n16    HO/56798/92     PA/424/92  0.367111              1      0      0      0   \n17     MA/G122/93      ST/20/93  0.369642              1      0      0      0   \n18     BI/1761/76    BI/5657/76  0.378665              1      0      0      0   \n19     BI/1761/76    BI/5029/76  0.379840              1      0      0      0   \n20      MA/G12/91    NI/3129/92  0.386476              1      0      0      0   \n21     NI/3126/92     PA/490/92  0.397200              1      0      1      0   \n22     LY/1189/91     PA/490/92  0.405961              1      0      1      0   \n23     UM/1982/92     PA/287/93  0.416677              1      0      0      0   \n24     BI/5930/74    BI/2813/75  0.422935              1      0      0      0   \n25       SP/53/89       SU/1/90  0.424534              1      0      0      0   \n26    LY/23602/93     NL/398/93  0.452428              1      0      0      0   \n27       YA/56/93      YA/62/93  0.459537              1      0      0      0   \n28     LY/1373/91   HO/56829/92  0.462278              1      0      0      0   \n29      NL/241/93      ST/20/93  0.475664              1      0      0      0   \n30    LY/23602/93     NL/241/93  0.494333              1      0      0      0   \n31      NL/398/93      ST/20/93  0.496009              1      0      0      0   \n...           ...           ...       ...            ...    ...    ...    ...   \n6497      SG/6/93    GE/3958/96  6.573208             10      0      0      0   \n6502    NL/115/93    GE/3958/96  6.610347             10      0      0      0   \n6503      AK/4/93    GE/3958/96  6.623533             10      0      0      0   \n6509    NL/101/93      HK/49/95  6.708715             10      0      0      0   \n6519   SE/C273/92    LY/2279/95  6.770741             10      0      0      0   \n6521     YA/62/93     FI/381/95  6.786840             10      0      0      0   \n6527     YA/62/93      SY/26/95  6.829389             10      0      0      0   \n6545     YA/62/93     FI/339/95  7.012575             10      0      0      0   \n6554    NL/115/93  GE/298971/95  7.056085             10      0      0      0   \n6581    NL/115/93     FI/381/95  7.234976             10      0      0      0   \n6582     YA/62/93  GE/298971/95  7.251526             10      0      0      0   \n6596   SE/C273/92     FI/381/95  7.353472             10      0      0      0   \n6600     YA/62/93    GE/3958/96  7.390370             10      0      0      0   \n6606   SE/C273/92      SY/26/95  7.430235             10      0      0      0   \n6609    NL/115/93      SY/26/95  7.459449             10      0      0      0   \n6610    NL/115/93     FI/339/95  7.468436             10      0      0      0   \n6619    NL/126/93    GE/3958/96  7.570188             10      0      0      0   \n6621   SE/C273/92     FI/339/95  7.583224             10      0      0      0   \n6629     YA/61/93    LY/2279/95  7.640246             10      0      0      0   \n6635   SE/C273/92  GE/298971/95  7.690787             10      0      0      0   \n6636   SE/C273/92    GE/3958/96  7.693362             10      0      0      0   \n6658     YA/61/93     FI/381/95  7.986947             10      0      0      0   \n6659     YA/61/93      SY/26/95  8.020867             10      0      0      0   \n6660    NL/126/93  GE/298971/95  8.026830             10      0      0      0   \n6668    NL/126/93     FI/381/95  8.173346             10      0      0      0   \n6670     YA/61/93     FI/339/95  8.211852             10      0      0      0   \n6682    NL/126/93      SY/26/95  8.381870             10      0      0      0   \n6684    NL/126/93     FI/339/95  8.407481             10      0      0      0   \n6685     YA/61/93  GE/298971/95  8.443632             10      0      0      0   \n6691     YA/61/93    GE/3958/96  8.528270             10      0      0      0   \n\n      AK135  AN124  AP304    ...     SV186  SY137  SY159  SY219  SY279  TY155  \\\n1         0      0      0    ...         0      0      0      0      0      0   \n2         0      0      0    ...         0      0      0      0      0      0   \n3         0      0      0    ...         0      0      0      0      0      0   \n4         0      0      0    ...         0      0      0      0      0      0   \n5         0      0      0    ...         0      0      0      0      0      0   \n6         0      0      0    ...         0      0      0      0      0      0   \n7         0      0      0    ...         0      0      0      0      0      0   \n9         0      0      0    ...         0      0      0      0      0      0   \n10        0      0      0    ...         0      0      0      0      0      0   \n11        0      0      0    ...         0      0      0      0      0      0   \n12        0      0      0    ...         0      0      0      0      0      0   \n13        0      0      0    ...         0      0      0      0      0      0   \n14        0      0      0    ...         0      0      0      0      0      0   \n15        0      0      0    ...         0      0      0      0      0      0   \n16        0      0      0    ...         0      0      0      0      0      0   \n17        0      0      0    ...         0      0      0      0      0      0   \n18        0      0      0    ...         0      0      0      0      0      0   \n19        0      0      0    ...         0      0      0      0      0      0   \n20        0      0      0    ...         0      0      0      0      0      0   \n21        0      0      0    ...         0      0      0      0      0      0   \n22        0      0      0    ...         0      0      0      0      0      0   \n23        0      0      0    ...         0      0      0      0      0      0   \n24        0      0      0    ...         0      0      0      0      0      0   \n25        0      0      0    ...         0      0      0      0      0      0   \n26        0      0      0    ...         0      0      0      0      0      0   \n27        0      0      0    ...         0      0      0      0      0      0   \n28        0      0      0    ...         0      0      0      0      0      0   \n29        0      0      0    ...         0      0      0      0      0      0   \n30        0      0      0    ...         0      0      0      0      0      0   \n31        0      0      0    ...         0      0      0      0      0      0   \n...     ...    ...    ...    ...       ...    ...    ...    ...    ...    ...   \n6497      0      0      0    ...         0      0      0      0      0      0   \n6502      0      0      0    ...         0      0      0      0      0      0   \n6503      0      0      0    ...         0      0      0      0      0      0   \n6509      0      0      0    ...         0      0      0      0      0      0   \n6519      0      0      0    ...         0      0      0      0      0      0   \n6521      0      0      0    ...         0      0      0      0      0      0   \n6527      0      0      0    ...         0      0      0      0      0      0   \n6545      0      0      0    ...         0      0      0      0      0      0   \n6554      0      0      0    ...         0      0      0      0      0      0   \n6581      0      0      0    ...         0      0      0      0      0      0   \n6582      0      0      0    ...         0      0      0      0      0      0   \n6596      0      0      0    ...         0      0      0      0      0      0   \n6600      0      0      0    ...         0      0      0      0      0      0   \n6606      0      0      0    ...         0      0      0      0      0      0   \n6609      0      0      0    ...         0      0      0      0      0      0   \n6610      0      0      0    ...         0      0      0      0      0      0   \n6619      0      0      0    ...         0      0      0      0      0      0   \n6621      0      0      0    ...         0      0      0      0      0      0   \n6629      0      0      0    ...         0      0      0      0      0      0   \n6635      0      0      0    ...         0      0      0      0      0      0   \n6636      0      0      0    ...         0      0      0      0      0      0   \n6658      0      0      0    ...         0      0      0      0      0      0   \n6659      0      0      0    ...         0      0      0      0      0      0   \n6660      0      0      0    ...         0      0      0      0      0      0   \n6668      0      0      0    ...         0      0      0      0      0      0   \n6670      0      0      0    ...         0      0      0      0      0      0   \n6682      0      0      0    ...         0      0      0      0      0      0   \n6684      0      0      0    ...         0      0      0      0      0      0   \n6685      0      0      0    ...         0      0      0      0      0      0   \n6691      0      0      0    ...         0      0      0      0      0      0   \n\n      strain_1_dates  strain_2_dates  cluster1  cluster2  \n1               1989            1990      BE89      BE89  \n2               1976            1976      VI75      VI75  \n3               1991            1992      BE89      BE92  \n4               1991            1992      BE89      BE92  \n5               1991            1992      BE89      BE92  \n6               1991            1992      BE89      BE92  \n7               1991            1992      BE89      BE92  \n9               1976            1976      VI75      VI75  \n10              1992            1992      BE92      BE92  \n11              1976            1976      VI75      VI75  \n12              1993            1994      BE92      BE92  \n13              1991            1991      BE89      BE89  \n14              1989            1989      BE89      BE89  \n15              1993            1993      BE92      BE92  \n16              1992            1992      BE92      BE92  \n17              1993            1993      BE92      BE92  \n18              1976            1976      VI75      VI75  \n19              1976            1976      VI75      VI75  \n20              1991            1992      BE89      BE92  \n21              1992            1992      BE92      BE92  \n22              1991            1992      BE89      BE92  \n23              1992            1993      BE92      BE92  \n24              1974            1975      EN72      VI75  \n25              1989            1990      BE89      BE89  \n26              1993            1993      BE92      BE92  \n27              1993            1993      BE92      BE92  \n28              1991            1992      BE89      BE92  \n29              1993            1993      BE92      BE92  \n30              1993            1993      BE92      BE92  \n31              1993            1993      BE92      BE92  \n...              ...             ...       ...       ...  \n6497            1993            1996      BE92      WU95  \n6502            1993            1996      BE92      WU95  \n6503            1993            1996      BE92      WU95  \n6509            1993            1995      BE92      WU95  \n6519            1992            1995      BE92      WU95  \n6521            1993            1995      BE92      WU95  \n6527            1993            1995      BE92      WU95  \n6545            1993            1995      BE92      WU95  \n6554            1993            1995      BE92      WU95  \n6581            1993            1995      BE92      WU95  \n6582            1993            1995      BE92      WU95  \n6596            1992            1995      BE92      WU95  \n6600            1993            1996      BE92      WU95  \n6606            1992            1995      BE92      WU95  \n6609            1993            1995      BE92      WU95  \n6610            1993            1995      BE92      WU95  \n6619            1993            1996      BE92      WU95  \n6621            1992            1995      BE92      WU95  \n6629            1993            1995      BE92      WU95  \n6635            1992            1995      BE92      WU95  \n6636            1992            1996      BE92      WU95  \n6658            1993            1995      BE92      WU95  \n6659            1993            1995      BE92      WU95  \n6660            1993            1995      BE92      WU95  \n6668            1993            1995      BE92      WU95  \n6670            1993            1995      BE92      WU95  \n6682            1993            1995      BE92      WU95  \n6684            1993            1995      BE92      WU95  \n6685            1993            1995      BE92      WU95  \n6691            1993            1996      BE92      WU95  \n\n[6723 rows x 307 columns]>\n","name":"stdout"}]},{"metadata":{"trusted":true,"collapsed":false},"cell_type":"code","source":["#Creating a dataset with interaction terms\n","iX = df.drop(['AG1', 'AG2', 'AG-DIST', 'NUM-MUTATIONS', \n","                   'strain_1_dates', 'strain_2_dates', 'cluster1', 'cluster2'], axis = 1)\n","for col1 in X.columns:\n","    for col2 in X.columns:\n","        if col1<col2:\n","            if max(iX[col1]*iX[col2]) >0:\n","                iX['%s:%s' %(col1, col2)] = (iX[col1]*iX[col2])\n","    "],"execution_count":52,"outputs":[]},{"metadata":{"trusted":true,"collapsed":false},"cell_type":"code","source":["ixtrain = iX.loc[((df['strain_1_dates']<=1994)& (df['strain_2_dates'] <=1994))]\n","ixtest = iX.loc[((df['strain_1_dates']>1994) |(df['strain_2_dates'] >1994))]\n",""],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["hdtest = np.array(test['NUM-MUTATIONS']).reshape(-1,1)\n","hdtrain = train['NUM-MUTATIONS']\n","hdtrain=np.array(hdtrain).reshape(-1,1)\n","print(hdtrain.shape)\n","\n","hdxtrain = train.drop(['AG1', 'AG2', 'AG-DIST', \n","                       'strain_1_dates', 'strain_2_dates', 'cluster1', 'cluster2'], axis = 1)\n","hdxtrain['NUM-MUTATIONS'] = train['NUM-MUTATIONS']\n","hdxtest = test.drop(['AG1', 'AG2', 'AG-DIST',\n","                     'strain_1_dates', 'strain_2_dates', 'cluster1', 'cluster2'], axis = 1)\n",""],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["cvlist = cv(train, 'cluster1', 'cluster2')"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["for tple in cvlist:\n","    assert set(tple[0]).isdisjoint(tple[1])"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Checking that the training and test data are disjoint\n","Looks good"]},{"metadata":{"collapsed":true,"trusted":true},"cell_type":"code","source":["fig_size = [8, 4]\n","plt.rcParams[\"figure.figsize\"] = fig_size\n"," \n","plt.hist((train[['strain_1_dates', 'strain_2_dates']].max(axis=1)), bins=range(1960,2004))\n","figure(2)\n","plt.hist((train[['strain_1_dates', 'strain_2_dates']].max(axis=1)), bins=range(1960,2004))\n","plt.hist((test[['strain_1_dates', 'strain_2_dates']].max(axis=1)), bins=range(1960,2004), color = 'g')\n",""],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#### Here's a function to plot the coefficients of a linear model"]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["def coefplot(coefs, cutoff = 0.01, interaction = False):\n","    fig_size = [20, 10]\n","    plt.rcParams[\"figure.figsize\"] = fig_size\n","    if interaction:\n","        params = pd.DataFrame(data = coefs, index = ixtrain.columns)\n","    else:\n","        params = pd.DataFrame(data = coefs, index = xtrain.columns)\n","    \n","    params = params.loc[(params[0]<-cutoff)|(params[0]>cutoff)]\n","    params = params.sort_values(0)\n","    fig, ax = plt.subplots()\n","    x = range(len(params.index))\n","    ax.scatter(x, list(params[0]), color=\"g\", s=10)\n","    xticks(x, x)\n","    ax.set_xlim([-1, len(params)])\n","    \n","    ax.set_xticklabels([\"\\n\".join(list(name)) for name in params.index],\n","                       fontsize=10)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Let's have a look at how far apart in years the antigenic distance comparisons we have are\n",""]},{"metadata":{"collapsed":true,"trusted":true},"cell_type":"code","source":["fig_size = [6, 3]\n","plt.rcParams[\"figure.figsize\"] = fig_size\n","\n","plt.hist(df['strain_2_dates']-df['strain_1_dates'], bins = range(16))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### What is the distribution of antigenic distances?\n",""]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["fig_size = [6, 3]\n","plt.rcParams[\"figure.figsize\"] = fig_size\n","\n","plt.hist(df['AG-DIST'], bins = 32)"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["def errorplot(clf, xtst):\n","    fig_size = [15, 6]\n","    plt.rcParams[\"figure.figsize\"] = fig_size\n","\n","    errors = ytest.to_frame()\n","    errors['ytest'] = ytest\n","    errors['predicted'] = clf.predict(xtst)\n","    errors['error'] = errors['ytest']-errors['predicted']\n","    errors['date'] = test['strain_2_dates']\n","    errors = errors.sort_values('error')\n","    #plt.figure(1)\n","    #plt.scatter(range(len(ytest)), errors['error'])\n","    #plt.xlim(0, len(ytest)+1)\n","    \n","    #plt.figure(2)\n","    #plt.scatter(range(len(ytest)), errors['ytest'], color = 'g')\n","    #plt.scatter(range(len(ytest)), errors['predicted'])\n","    #plt.scatter(range(len(ytest)), errors['error'], color = 'r')\n","    \n","    plt.figure(3)\n","    errors = errors.sort_values('date')\n","    errors['jittered_dates'] = errors['date'] + np.random.uniform(-2, 2, len(test))\n","    plt.scatter(errors['jittered_dates'], errors['ytest'], color = 'g')\n","    plt.scatter(errors['jittered_dates'], errors['predicted'], color = 'b')\n","    plt.scatter(errors['jittered_dates'], errors['error'], color = 'r')\n","    \n","    plt.figure(4)\n","    plt.hist(errors['error'])"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Now we try fitting various ml models"]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["clf=sklm.LinearRegression()\n","clf.fit(xtrain, ytrain)\n","score=clf.score(xtest, ytest)\n","print(score)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Oh dear, that didn't work very well. Let's have a look at the coefficients."]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["coefplot(clf.coef_)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["It looks like quite a few of the coefficients are quite strongly negative, and most of them are zero\n","\n","### As a baseline, how well can we do with just Hamming Distances?"]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["hdclf=sklm.LinearRegression()\n","hdclf.fit(hdtrain, ytrain)\n","score=hdclf.score(hdtest, ytest)\n","print(score)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["This is better than Oskar's model.\n","Anything below an r^2 of 0.55 is worse than just counting the number of mutations"]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["fig_size = [15, 15]\n","plt.rcParams[\"figure.figsize\"] = fig_size\n","jitteredHD = df['NUM-MUTATIONS'] + np.random.uniform(-0.3, 0.3, len(df))\n","plt.xlabel('NUM-MUTATIONS')\n","plt.ylabel('AG-DIST')\n","plt.scatter(jitteredHD, df['AG-DIST'])\n","plt.xlim(0,26)\n","plt.ylim(0,17)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["errorplot(hdclf, hdtest)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Now let's try a regularized linear regression"]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["scores1 = []\n","for a in [0.01, 0.1, 1, 10 , 100, 1000, 1500, 2000, 3000]:\n","    clf1 = sklm.Ridge(alpha = a)\n","    clf1.fit(xtrain, ytrain)\n","    scores1.append(clf1.score(xtest, ytest))\n","print(scores1)"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["scores1 = []\n","scores2 = []\n","for a in [5, 10, 20, 40, 80, 100, 200, 300, 400]:\n","    clf1 = sklm.Ridge(alpha = a)\n","    clf1.fit(xtrain, ytrain)\n","    scores1.append(clf1.score(xtest, ytest))\n","    scores2.append(clf1.score(xtrain,ytrain))\n","print(scores1)\n","\n","print('The fit on the training data is')\n","print(scores2)\n",""],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":false},"cell_type":"code","source":["clf = sklm.Ridge(alpha = 300)\n","clf.fit(xtrain,ytrain)\n","clf.score(xtest, ytest)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#### Let's see what the errors look like"]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["errorplot(clf, xtest)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":false},"cell_type":"code","source":["coefplot(clf.coef_)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### What happens if we include hamming distance in the model?"]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["\n","scores1 = []\n","for a in [5, 10, 20, 40, 80, 100, 200, 300, 400]:\n","    clf1 = sklm.Ridge(alpha = a)\n","    clf1.fit(hdxtrain, ytrain)\n","    scores1.append(clf1.score(hdxtest, ytest))\n","print(scores1)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Seems like accuracy is slightly worse but basically the same. The errors look pretty similar, maybe a tiny bit better around the extremes"]},{"metadata":{},"cell_type":"markdown","source":["### Let's try a lasso penalised regression, and force the coefficients to be positive"]},{"metadata":{"trusted":true,"collapsed":false},"cell_type":"code","source":["scores =[]\n","for a in [0.001, 0.005, 0.008, 0.009, 0.01, 0.015, 0.05, 0.1, 1]:\n","    clf1 = sklm.Lasso(alpha = a, positive=True)\n","    clf1.fit(xtrain, ytrain)\n","    scores.append(clf1.score(xtest, ytest))\n","print(scores)\n",""],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":false},"cell_type":"code","source":["clf = sklm.Lasso(alpha = 0.015, positive=True)\n","clf.fit(xtrain, ytrain)\n","clf.score(xtest, ytest)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["coefplot(clf.coef_, True)\n","plt.figure(2)\n","coefplot(clf.coef_, False)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Let's try including the interaction terms in a lasso model"]},{"metadata":{"trusted":true,"collapsed":false},"cell_type":"code","source":["iscores =[]\n","for a in [0.001, 0.005, 0.008, 0.009, 0.01, 0.015, 0.05, 0.1, 1]:\n","    iclf = sklm.Lasso(alpha = a, positive=True)\n","    iclf.fit(ixtrain, ytrain)\n","    iscores.append(iclf.score(ixtest, ytest))\n","print(iscores)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":false},"cell_type":"code","source":["iscores =[]\n","for a in [0.01, 0.015, 0.05, 0.1, 0.2, 0.3]:\n","    iclf = sklm.Lasso(alpha = a)\n","    iclf.fit(ixtrain, ytrain)\n","    iscores.append(iclf.score(ixtest, ytest))\n","print(iscores)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":false},"cell_type":"code","source":["iclf = sklm.Lasso(alpha = 0.1 )\n","iclf.fit(ixtrain, ytrain)\n","iclf.score(ixtest, ytest)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["coefplot(iclf.coef_, True, True)\n","plt.figure(2)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":false},"cell_type":"code","source":["def getcoefs(coefs, omitsmall = True):\n","    cfs = pd.DataFrame(data = coefs, index = ixtrain.columns)\n","    if omitsmall:\n","        cfs = cfs.loc[(cfs[0]<-0.1)|(cfs[0]>0.1)]\n","    cfs = cfs.sort_values(0)\n","    return cfs\n",""],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["The distances for the 3 interaction terms (from right to left) are 52.3, 26.8 and 14.9. \n","\n","52.3 is too far apart to be a plausible distance, but 26.8 and 14.9 seem to be valid interaction terms\n","\n","Let's find out whether DE190 and NT276 ever occur apart"]},{"metadata":{"trusted":true,"collapsed":false},"cell_type":"code","source":["print(sum(ixtrain['NT276']))\n","print(sum(ixtrain['DE190']))\n","print(sum(ixtrain['NT276'] & (ixtrain['DE190'])))\n","print(sum(ixtrain['NT276'] & ~(ixtrain['DE190'])))\n","print(sum(~(ixtrain['NT276']) & (ixtrain['DE190'])))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":false},"cell_type":"code","source":["getcoefs(iclf.coef_)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Let's try using interaction terms with a ridge model"]},{"metadata":{"trusted":true,"collapsed":false},"cell_type":"code","source":["iscores =[]\n","for a in [0.01, 0.1, 1, 10, 100, 1000]:\n","    iclf = sklm.Ridge(alpha = a)\n","    iclf.fit(ixtrain, ytrain)\n","    iscores.append(iclf.score(ixtest, ytest))\n","print(iscores)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":false},"cell_type":"code","source":["iscores =[]\n","for a in [100, 1000, 2000, 5000, 10000]:\n","    iclf = sklm.Ridge(alpha = a)\n","    iclf.fit(ixtrain, ytrain)\n","    iscores.append(iclf.score(ixtest, ytest))\n","print(iscores)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":false},"cell_type":"code","source":["iclf = sklm.Ridge(alpha = 5000 )\n","iclf.fit(ixtrain, ytrain)\n","iclf.score(ixtest, ytest)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":false},"cell_type":"code","source":["coefplot(iclf.coef_, cutoff=0.1, interaction=True)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["This model has far too many terms and gets a worse fit than using the ridge model without interaction terms - I guess it's overfitting"]},{"metadata":{},"cell_type":"markdown","source":["### Let's try using support vector machines!"]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["clf2 = svm.SVR()\n","clf2.fit(xtrain, ytrain)\n","svmscore=clf2.score(xtest, ytest)\n","print(svmscore)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["errorplot(clf2, xtest)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### These are pretty slow. Let's try random forests"]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["num = [10, 50, 200, 500, 1000]\n","depth= [5,10, 12, 15, 20, 30, 40]\n","scores=np.empty([len(depth)+1, len(num)+1])\n","scores[0,1:] = num\n","scores[1:,0] = depth"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["for i in range(len(num)):\n","    for j in range(len(depth)):\n","        clf3 = ensemble.RandomForestRegressor(n_estimators=num[i], max_depth=depth[j])\n","        clf3.fit(xtrain, ytrain)\n","        rfscore=clf3.score(xtest, ytest)\n","        scores[j+1][i+1]=rfscore\n","print(scores)\n",""],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["The scores are significantly worse than the linear model. "]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["num2 = [5, 10, 15, 20, 30, 40]\n","maxlf= [10, 50, 100, 200, 500]\n","scores2=np.empty([len(maxlf)+1, len(num2)+1])\n","scores2[0,1:] = num2\n","scores2[1:,0] = maxlf"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["for i in range(len(num2)):\n","    for j in range(len(maxlf)):\n","        clf3 = ensemble.RandomForestRegressor(n_estimators=num2[i], max_leaf_nodes=maxlf[j])\n","        clf3.fit(xtrain, ytrain)\n","        rfscore=clf3.score(xtest, ytest)\n","        scores2[j+1][i+1]=rfscore\n","print(scores2)"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["clf4 = ensemble.RandomForestRegressor(n_estimators=11, max_leaf_nodes=100)\n","clf4.fit(xtrain, ytrain)\n","rfscore2=clf4.score(xtest, ytest)\n","print(rfscore2)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":false},"cell_type":"code","source":["coefplot(clf4.feature_importances_)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":false},"cell_type":"code","source":["errorplot(clf4, xtest)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["The errors here are pretty skewed towards overestimating the distances - interesting"]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["lolo = LeaveOneLabelOut(train['cluster1'])\n","cvscores = cross_val_score(clf4, xtrain, ytrain, cv = lolo)\n","print(cvscores)\n",""],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":false},"cell_type":"code","source":["train.cluster1.value_counts().plot(kind='bar', color = 'b')\n","train.cluster2.value_counts().plot(kind='bar', color = 'g')\n","print(train.cluster1.shape)\n","print(train.cluster2.shape)"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["customcvscores = cross_val_score(clf4, xtrain, ytrain, cv = cvlist)\n","print(customcvscores)"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["scores3=np.empty([7,6])\n","cvar = [0.01, 0.1, 1, 10, 100]\n","epsilonvar= [0.001, 0.01, 0.1, 1, 10, 100]\n","scores3[0,1:] = cvar\n","scores3[1:,0] = epsilonvar"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["for i in range(5):\n","    for j in range(6):\n","        clf5 = svm.SVR(C = cvar[i], epsilon = epsilonvar[j])\n","        clf5.fit(xtrain, ytrain)\n","        svmscore=clf5.score(xtest, ytest)\n","        scores3[j+1][i+1]=svmscore\n","print(scores3)"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["scores4=np.empty([7,6])\n","cvar = [0.5, 1, 2, 4, 10]\n","epsilonvar= [0.001, 0.01, 0.1, 0.5, 1, 2]\n","scores4[0,1:] = cvar\n","scores4[1:,0] = epsilonvar\n","\n","for i in range(5):\n","    for j in range(6):\n","        clf5 = svm.SVR(C = cvar[i], epsilon = epsilonvar[j])\n","        clf5.fit(xtrain, ytrain)\n","        svmscore=clf5.score(xtest, ytest)\n","        scores4[j+1][i+1]=svmscore\n","print(scores4)"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["with open('svm scores grid 2', 'w') as f:\n","    f.write(repr(scores4))"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["np.set_printoptions(precision=3)\n","np.set_printoptions(suppress=True)\n","\n","print(scores4)"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["scores5=np.empty([6,3])\n","cvar = [0.5,10]\n","epsilonvar= [0.5, 0.8, 1, 1.2, 1.4]\n","scores5[0,1:] = cvar\n","scores5[1:,0] = epsilonvar\n","\n","for i in range(2):\n","    for j in range(5):\n","        clf5 = svm.SVR(C = cvar[i], epsilon = epsilonvar[j])\n","        clf5.fit(xtrain, ytrain)\n","        svmscore=clf5.score(xtest, ytest)\n","        scores5[j+1][i+1]=svmscore\n","print(scores5)"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["\n","n_estimators = [5, 10, 20, 25, 30, 35]\n","learnrate= [0.01, 0.1, 1, 10, 15, 20, 40]\n","ABscores=np.empty([len(learnrate)+1, len(n_estimators)+1])\n","ABscores[0,1:] = n_estimators\n","ABscores[1:,0] = learnrate\n","\n","\n","for i in range(len(learnrate)):\n","    for j in range(len(n_estimators)):\n","        ABclf = sk.ensemble.AdaBoostRegressor(n_estimators=n_estimators[j], learning_rate=learnrate[i])\n","        ABclf.fit(xtrain, ytrain)\n","        ABscores[i+1,j+1] = ABclf.score(xtest, ytest)\n","        \n","print(ABscores)\n",""],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":false},"cell_type":"code","source":["n_estimators = [5, 10, 20, 25, 30, 35]\n","learnrate= [0.1, 1, 2, 5]\n","ABscores=np.empty([len(learnrate)+1, len(n_estimators)+1])\n","ABscores[0,1:] = n_estimators\n","ABscores[1:,0] = learnrate\n","\n","\n","for i in range(len(learnrate)):\n","    for j in range(len(n_estimators)):\n","        ABclf = sk.ensemble.AdaBoostRegressor(n_estimators=n_estimators[j], learning_rate=learnrate[i])\n","        ABclf.fit(xtrain, ytrain)\n","        ABscores[i+1,j+1] = ABclf.score(xtest, ytest)\n","        \n","print(ABscores)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":false},"cell_type":"code","source":["ABclf = sk.ensemble.AdaBoostRegressor(n_estimators=30, learning_rate=0.1)\n","ABclf.fit(xtrain, ytrain)\n","ABclf.score(xtest, ytest)"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["coefplot(ABclf.feature_importances_, cutoff = 0.01)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["n_estimators = [5, 10, 20, 25, 30, 35]\n","learnrate= [0.1, 1, 2, 5]\n","ABscores=np.empty([len(learnrate)+1, len(n_estimators)+1])\n","ABscores[0,1:] = n_estimators\n","ABscores[1:,0] = learnrate\n","\n","\n","for i in range(len(learnrate)):\n","    for j in range(len(n_estimators)):\n","        ABclf = sk.ensemble.AdaBoostRegressor(n_estimators=n_estimators[j], learning_rate=learnrate[i])\n","        ABclf.fit(ixtrain, ytrain)\n","        ABscores[i+1,j+1] = ABclf.score(ixtest, ytest)\n","        \n","print(ABscores)"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":true},"cell_type":"raw","source":["cvscores = cross"]},{"metadata":{"collapsed":false,"trusted":true},"cell_type":"code","source":["# Grid search with 10-fold cross-validation using a dictionary of parameters\n","\n","# Create the dictionary of given parameters\n","n_estimators = [5, 10, 20, 40, 80]\n","learnrate= [0.01, 0.1, 1, 10]\n","parameters  = [{'n_estimators': n_estimators, 'learnrate': learnrate}] \n","\n","# Optimise and build the model with GridSearchCV\n","gridCV = grid_search.GridSearchCV(ensemble.AdaBoostRegressor, parameters, cv=cvlist)\n","gridCV.fit(xtrain, ytrain) \n","\n","# Report the optimal parameters\n","bestNeighbors = gridCV.best_params_['n_estimators']\n","bestWeight    = gridCV.best_params_['learnrate']\n","\n","print(\"Best parameters: n_estimators=\", bestNeighbors, \"and learnrate=\", bestWeight)\n",""],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}